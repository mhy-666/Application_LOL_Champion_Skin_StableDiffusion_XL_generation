{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_champion_urls():    \n",
    "    champion = []\n",
    "    with open('../data/raw/champion.txt','r') as f:\n",
    "        for line in f:\n",
    "            cleaned_line = ''.join(e for e in line.strip() if e.isalnum())\n",
    "            champion.append(cleaned_line.lower())\n",
    "    champion_urls = []\n",
    "    for c in champion:\n",
    "        if c == 'renataglasc':\n",
    "            c = 'renata'\n",
    "        champion_urls.append('https://www.skinexplorer.lol/champions/'+c)\n",
    "    return champion_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n"
     ]
    }
   ],
   "source": [
    "champion_urls = get_champion_urls()\n",
    "print(len(champion_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.skinexplorer.lol/champions/renata\n"
     ]
    }
   ],
   "source": [
    "# champion_urls.index('renataglasc')\n",
    "print(champion_urls[97])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_url(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    download_link = soup.find('main', style=\"transform:translateX(0)\").find('img')['src']\n",
    "    return download_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url, save_path):\n",
    "    response = requests.get(image_url)\n",
    "    with open(save_path, 'wb') as file:\n",
    "        file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_thumbnail_links(champion_urls):\n",
    "    for url in champion_urls[97:]:\n",
    "        # Send HTTP request\n",
    "        \n",
    "        response = requests.get(url)\n",
    "        webpage = response.text\n",
    "        champion_name = url.split('/')[-1]\n",
    "        print(champion_name)\n",
    "        # Parse the webpage\n",
    "        soup = BeautifulSoup(webpage, 'html.parser')\n",
    "        # Find the thumbnail links\n",
    "        # Note: 'thumbnail_class' should be replaced with the actual HTML class name of the thumbnail links\n",
    "        thumbnails = soup.find_all('div', class_=\"styles_grid__4dc4K\")\n",
    "        thumbnails = thumbnails[0].find_all('a')\n",
    "        # Get the thumbnail page links\n",
    "        thumbnail_urls = []\n",
    "        thumbnail_urls = ['https://www.skinexplorer.lol'+thumb['href'] for thumb in thumbnails]\n",
    "        \n",
    "        full_image_urls = [get_image_url(url) for url in thumbnail_urls]\n",
    "        # Download the images\n",
    "        for i, img_url in enumerate(full_image_urls):\n",
    "            download_image(img_url, f'../data/raw/images/{champion_name}_{i}.jpg')            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "renata\n",
      "renekton\n",
      "rengar\n",
      "riven\n",
      "rumble\n",
      "ryze\n",
      "samira\n",
      "sejuani\n",
      "senna\n",
      "seraphine\n",
      "sett\n",
      "shaco\n",
      "shen\n",
      "shyvana\n",
      "singed\n",
      "sion\n",
      "sivir\n",
      "skarner\n",
      "sona\n",
      "soraka\n",
      "swain\n",
      "sylas\n",
      "syndra\n",
      "tahmkench\n",
      "taliyah\n",
      "talon\n",
      "taric\n",
      "teemo\n",
      "thresh\n",
      "tristana\n",
      "trundle\n",
      "tryndamere\n",
      "twistedfate\n",
      "twitch\n",
      "udyr\n",
      "urgot\n",
      "varus\n",
      "vayne\n",
      "veigar\n",
      "velkoz\n",
      "vex\n",
      "vi\n",
      "viego\n",
      "viktor\n",
      "vladimir\n",
      "volibear\n",
      "warwick\n",
      "wukong\n",
      "xayah\n",
      "xerath\n",
      "xinzhao\n",
      "yasuo\n",
      "yone\n",
      "yorick\n",
      "yuumi\n",
      "zac\n",
      "zed\n",
      "zeri\n",
      "ziggs\n",
      "zilean\n",
      "zoe\n",
      "zyra\n",
      "belveth\n",
      "nilah\n",
      "ksante\n",
      "milio\n",
      "naafiri\n",
      "briar\n",
      "hwei\n",
      "smolder\n"
     ]
    }
   ],
   "source": [
    "get_thumbnail_links(champion_urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
